{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Recalibrating the ringdown attachment frequency for ENIGMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    " - The idea here is to use an MCMC algorithm to find the best parameters that make ENIGMA agree with SEOBNRv4 in the regions of parameter space that overlap for them\n",
    " - We will use the emcee package for this\n",
    " - We need a few components for MCMC:\n",
    "    - A way to generate ENIGMA for a given set of parameters **$\\theta$**\n",
    "\n",
    "\n",
    "**Define**:\n",
    "\n",
    " 1. Fix $\\{m_1, m_2\\}$\n",
    " 1. $\\theta = \\{\\omega_\\mathrm{attach}, \\,\\mathrm{PN\\, order}\\}$\n",
    " 1. ndim = len(\\theta) = 2\n",
    " 1. log_prob $\\propto \\langle h_1, h_2 \\rangle$ \n",
    "\n",
    "**Choose internal parameters**:\n",
    "\n",
    " 1. PSD $\\in$ [**aLIGOZeroDetHighPower**, **Flat**]\n",
    " 2. low frequency cutoff $\\in [15, 20, 30]Hz$\n",
    " 2. sample rate = $2048$\n",
    " 2. masses $(m_1, m_2) \\in [40, 60]M_\\odot$\n",
    " 2. attachment time $t_\\mathrm{attach} \\in $ **???**\n",
    " 2. attachment time window $dt_\\mathrm{attach} \\in $ **???**\n",
    "\n",
    "**Algorithm**:\n",
    "\n",
    "* Sample $\\theta$:\n",
    " 1. PNO $\\in [6, 7, 8, 9, 10, 11, 12]$\n",
    " 1. $\\omega_\\mathrm{attach} \\in [0.01, 0.1]$\n",
    "* Do:\n",
    " 1. Compute $h_1 \\equiv$ h_ENIGMA$\\left(m_1, m_2, \\theta; t\\right)$\n",
    " 1. Compute $h_2 \\equiv$ h_EOB$\\left(m_1, m_2, \\theta; t\\right)$\n",
    " 1. Compute log_prob = $\\propto \\langle h_1, h_2 \\rangle$\n",
    "\n",
    "**Code plan**:\n",
    "\n",
    "* `gwnrtools_enigma_plan_grid_and_make_dag`\n",
    " - Inputs:\n",
    "   - mass1 range, num_points\n",
    "   - mass2 range, num_points\n",
    "   - f_lower choices\n",
    "   - psd choices\n",
    "   - num_unique_mcmc_per_job\n",
    " - Meat:\n",
    "   - Generate a hypercubic lattice over {mass1, mass2, f_lower, psd_choices}\n",
    "   - \n",
    " - Output:\n",
    "   - DAG\n",
    "* `gwnrtools_enigma_sample_parameters`\n",
    " - Inputs:\n",
    "   - Fixed values of mass1\n",
    "   - Fixed values of mass2\n",
    "   - Fixed values of f_lower\n",
    "   - Fixed values of psd\n",
    " - Meat:\n",
    "   - Iterate over {mass1, mass2, f_lower, psd_choices}\n",
    "   - MCMC over $\\{\\omega_\\mathrm{attach}, \\mathrm{PNO}\\}$\n",
    " - Output:\n",
    "   - Text file with columns:\n",
    "     - [1] mass-ratio\n",
    "     - [2] total-mass\n",
    "     - [3] mass1\n",
    "     - [4] mass2\n",
    "     - [5] ecc value\n",
    "     - [6] PN order\n",
    "     - [7] omega_attach\n",
    "     - [8] overlap\n",
    "     - [9] Re[unphase-maximized overlap]\n",
    "     - [10] Im[unphase-maximized overlap]\n",
    "     - [11] norm1\n",
    "     - [12] norm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import h5py\n",
    "import emcee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from pycbc.waveform import get_td_waveform, get_fd_waveform\n",
    "from pycbc.psd import from_string\n",
    "from pycbc.filter import match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.join(os.environ['HOME'], 'src/GWNRTools'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import GWNRTools as gwnrtools\n",
    "from GWNRTools.Utils import make_padded_frequency_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "run_directory = '/home/prayush/TESTME'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## `gwnrtools_enigma_plan_grid_and_make_dag`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Code plan**:\n",
    "\n",
    "* `gwnrtools_enigma_plan_grid_and_make_dag`\n",
    " - Inputs:\n",
    "   - mass1 range, num_points\n",
    "   - mass2 range, num_points\n",
    "   - f_lower choices\n",
    "   - psd choices\n",
    "   - num_unique_mcmc_per_job\n",
    " - Meat:\n",
    "   - Generate a hypercubic lattice over {mass1, mass2, f_lower, psd_choices}\n",
    "   - \n",
    " - Output:\n",
    "   - DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# fake inputs\n",
    "range_of_mass1 = np.array([3., 100.])\n",
    "range_of_mass2 = np.array([3., 100.])\n",
    "range_of_q = np.array([1., 10.])\n",
    "\n",
    "spacing_mass1 = 1.0\n",
    "spacing_mass2 = 1.0\n",
    "\n",
    "choices_f_lower = np.array([15., 30.])\n",
    "\n",
    "choices_psd = ['aLIGOZeroDetHighPower']\n",
    "\n",
    "num_unique_mcmc_per_job = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Move to run directory\n",
    "if not os.path.exists(run_directory):\n",
    "    os.makedirs(run_directory)\n",
    "os.chdir(run_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Make directories\n",
    "dirs_to_make = ['input', 'results']\n",
    "\n",
    "for d in dirs_to_make:\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "\n",
    "\n",
    "def job_id(job_num):\n",
    "    return '{:06d}'.format(job_num)\n",
    "\n",
    "def write_parameter_file(job_id, params):\n",
    "    file_name = os.path.join('input/parameters_{0}.hdf'.format(job_id))\n",
    "    if os.path.exists(file_name):\n",
    "        return file_name\n",
    "    with h5py.File(file_name) as fout:\n",
    "        for param_name in params:\n",
    "            fout.create_dataset(param_name, data = params[param_name])\n",
    "    return file_name\n",
    "\n",
    "def dag_file():\n",
    "    return 'retune_enigma.dag'\n",
    "\n",
    "def write_job_to_dag(job_id, param_file):\n",
    "    with open(dag_file(), 'a+') as fout:\n",
    "        fout.write('''\\\n",
    "JOB TUNE{0} sampler.submit\n",
    "VARS TUNE{0} macroparamfile=\"{1}\"\n",
    "\n",
    "'''.format(job_id, param_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "* Make the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "jobs = {}\n",
    "\n",
    "num_mcmc_in_job = 1e9\n",
    "job_num = 0\n",
    "job_params = None\n",
    "\n",
    "for m1 in np.arange(range_of_mass1[0], range_of_mass1[-1], spacing_mass1):\n",
    "    for m2 in np.arange(range_of_mass2[0], range_of_mass2[-1], spacing_mass2):\n",
    "        q = m1 / m2\n",
    "        if q < range_of_q[0] or q > range_of_q[-1]:\n",
    "            continue\n",
    "        \n",
    "        for f_lower in choices_f_lower:\n",
    "            for psd_name in choices_psd:\n",
    "                # prepare the job                \n",
    "                if num_mcmc_in_job < num_unique_mcmc_per_job:\n",
    "                    # add to current job\n",
    "                    job_params.append([m1, m2, f_lower, psd_name])\n",
    "                    \n",
    "                    num_mcmc_in_job += 1\n",
    "                    job_num += 1\n",
    "                    \n",
    "                else:\n",
    "                    # close current job\n",
    "                    if job_params:\n",
    "                        jobs[curr_job_id] = job_params\n",
    "                    \n",
    "                    # start new job\n",
    "                    curr_job_id = job_id(job_num)\n",
    "                    job_params = [[m1, m2, f_lower, psd_name]]\n",
    "                    \n",
    "                    num_mcmc_in_job = 0\n",
    "                    job_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "* Write submit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "submit_text = '''\\\n",
    "universe = vanilla\n",
    "executable = scripts/gwnrtools_enigma_sample_parameters\n",
    "arguments = \" --parameter-file $(macroparamfile) \"\n",
    "accounting_group = ligo.dev.o3.cbc.explore.test\n",
    "getenv = True\n",
    "log = /usr1/prayush.kumar/tmpc8uHuQ\n",
    "error = log/gwnrtools_enigma_sample_parameters-$(cluster)-$(process).err\n",
    "output = log/gwnrtools_enigma_sample_parameters-$(cluster)-$(process).out\n",
    "notification = never\n",
    "queue 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with open(\"sampler.sub\", \"w\") as fout:\n",
    "    fout.write(submit_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "* Design DAG\n",
    "  * Iterate over the grid, and add a job for each!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for job_id in jobs:\n",
    "    job_params = jobs[job_id]\n",
    "    \n",
    "    # m1, m2, f_lower, psd\n",
    "    job_p0_vals = [p[0] for p in job_params]\n",
    "    job_p1_vals = [p[1] for p in job_params]\n",
    "    job_p2_vals = [p[2] for p in job_params]\n",
    "    job_p3_vals = [p[3] for p in job_params]\n",
    "    \n",
    "    job_params_dict = {\n",
    "        'mass1' : job_p0_vals,\n",
    "        'mass2' : job_p1_vals,\n",
    "        'f_lower' : job_p2_vals,\n",
    "        'psd' : job_p3_vals\n",
    "    }\n",
    "    \n",
    "    parameter_file_name = write_parameter_file(job_id, job_params_dict)\n",
    "    write_job_to_dag(job_id, parameter_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## `gwnrtools_enigma_sample_parameters`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Code plan**\n",
    "\n",
    "* `gwnrtools_enigma_sample_parameters`:\n",
    " - Inputs:\n",
    "   - Parameter file\n",
    " - Meat:\n",
    "   - Iterate over {mass1, mass2, f_lower, psd_choices}\n",
    "   - MCMC over $\\{\\omega_\\mathrm{attach}, \\mathrm{PNO}\\}$\n",
    " - Output:\n",
    "   - Text file with columns:\n",
    "     - [1] mass-ratio\n",
    "     - [2] total-mass\n",
    "     - [3] mass1\n",
    "     - [4] mass2\n",
    "     - [5] ecc value\n",
    "     - [6] PN order\n",
    "     - [7] omega_attach\n",
    "     - [8] overlap\n",
    "     - [9] Re[unphase-maximized overlap]\n",
    "     - [10] Im[unphase-maximized overlap]\n",
    "     - [11] norm1\n",
    "     - [12] norm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "os.chdir(run_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Fake inputs\n",
    "param_file = 'input/parameters_006000.hdf'\n",
    "sample_rate = 4096\n",
    "time_length = 32\n",
    "f_lower     = 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "delta_t = 1. / sample_rate\n",
    "delta_f = 1. / time_length\n",
    "N = sample_rate * time_length\n",
    "n = N / 2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fin = h5py.File(param_file, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "* Capture inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inputs = {}\n",
    "with h5py.File(param_file, 'r') as fin:\n",
    "    for k in fin:\n",
    "        inputs[k] = fin[k][()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "* Function for the log(probability) calculation to be used by the MCMC sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def get_sampler(log_probability, myarglist,\n",
    "                nwalkers = 32,\n",
    "                omega_attach_lims = [0.01, 0.1],\n",
    "                PNO_choices = [6, 7, 8, 9, 10, 11, 12]):\n",
    "    \"\"\"\n",
    "Function to Initialize and burn-in MCMC sampler\n",
    "    \"\"\"\n",
    "    # Setup hyper-parameters for the sampler\n",
    "    ndim = 2\n",
    "    \n",
    "    # Initialize emsemble sampler\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability, args=myarglist)\n",
    "    \n",
    "    # Run the sampler for a few steps to burn-in,\n",
    "    # ie erase memory of the starting locations\n",
    "    p0 = np.hstack([np.random.uniform(omega_attach_lims[0],\n",
    "                                      omega_attach_lims[-1],\n",
    "                                      (nwalkers,1)),\n",
    "                    np.random.uniform(PNO_choices[0] - 0.5,\n",
    "                                      PNO_choices[-1] + 0.5,\n",
    "                                      (nwalkers,1))])    \n",
    "    state = sampler.run_mcmc(p0, 100)\n",
    "    sampler.reset()\n",
    "    return sampler, state\n",
    "\n",
    "def write_output_from_sampler(output_file_name, sampler, myargs):\n",
    "    \"\"\"\n",
    "Function to write output of ONE MCMC sampler to txt file\n",
    "    \"\"\"\n",
    "    m1, m2, f_low, _ = myargs\n",
    "    with open(output_file_name, 'w+') as fout:\n",
    "        for p in sampler.chain():\n",
    "            # extracted sampled params and likelihood value\n",
    "            pno = 1\n",
    "            omega_att = -1\n",
    "            mch = 1e9\n",
    "            # write samples\n",
    "            fout.write(\\\n",
    "                \"{0:.18e}\\t{1:.18e}\\t{2:.18e}\\t{3:.18e}\\t{4:.18e}\\t{5:.18e}\\t{6:.18e}\\t{7:.18e}\".format(\\\n",
    "                    m1 / m2, m1 + m2, m1, m2, 0.0, pno, omega_att, mch))\n",
    "    return\n",
    "\n",
    "def log_prior_enigma(theta,\n",
    "                     omega_attach_lims = [0.01, 0.1],\n",
    "                     PNO_choices = [6, 7, 8, 9, 10, 11, 12]):\n",
    "    '''\n",
    "Priors:\n",
    "-------\n",
    "\n",
    "omega_attach : [0.01, 0.1]\n",
    "PNO : [6, 7, 8, 9, 10, 11, 12]\n",
    "    '''\n",
    "    omega_attach, PNO = theta\n",
    "    PNO = int(np.round(PNO))\n",
    "    if PNO not in PNO_choices:\n",
    "        return -np.inf\n",
    "    if omega_attach < omega_attach_lims[0] or omega_attach > omega_attach_lims[-1]:\n",
    "        return -np.inf\n",
    "    \n",
    "    return 0.0\n",
    "\n",
    "def log_likelihood(theta, mass1, mass2, f_lower, sample_rate, psd):\n",
    "    # extract MCMC parameters\n",
    "    omega_attach, PNO = theta\n",
    "    PNO = int(np.round(PNO))\n",
    "    \n",
    "    # Use BASH MAGIC TO PASS MCMC parameters TO ENIGMA\n",
    "    os.environ['OMEGA_ATTACH'] = '{0:.12f}'.format(omega_attach)\n",
    "    os.environ['PN_ORDER']     = '{0:d}'.format(PNO)\n",
    "    \n",
    "    dt = 1. / sample_rate\n",
    "    df = psd.delta_f\n",
    "    N = int(sample_rate / psd.delta_f)\n",
    "    \n",
    "    # Generate ENIGMA wave\n",
    "    try:\n",
    "        h1 = get_td_waveform(approximant='ENIGMA',\n",
    "                         mass1=mass1,\n",
    "                         mass2=mass2,\n",
    "                         f_lower=f_lower,\n",
    "                         delta_t=dt)\n",
    "    except:\n",
    "        logging.error(\"Could not generate ENIGMA wave..\")\n",
    "    h1 = make_padded_frequency_series(h1, N, df)\n",
    "    \n",
    "    # Generate EOB wave\n",
    "    try:\n",
    "        h2 = get_fd_waveform(approximant='SEOBNRv4_ROM',\n",
    "                         mass1=mass1,\n",
    "                         mass2=mass2,\n",
    "                         f_lower=f_lower,\n",
    "                         delta_f=df)\n",
    "    except:\n",
    "        logging.error(\"Could not generate EOB wave..\")\n",
    "    h2 = make_padded_frequency_series(h2, N, df)\n",
    "    \n",
    "    # Undo BASH MAGIC TO PASS MCMC parameters TO ENIGMA\n",
    "    os.environ['OMEGA_ATTACH'] = ''\n",
    "    os.environ['PN_ORDER']     = ''\n",
    "    \n",
    "    # Compute inner prodcut\n",
    "    log_like, _ = match(h1, h2, psd=psd, low_frequency_cutoff=f_lower)\n",
    "    return log_like\n",
    "\n",
    "def log_prob(theta, mass1, mass2, f_lower, sample_rate, psd):\n",
    "    log_prior = log_prior_enigma(theta)\n",
    "    if log_prior > -np.inf:\n",
    "        print(\"YAY: sampling within prior...\")\n",
    "        return log_likelihood(theta, mass1, mass2, f_lower, sample_rate, psd) + log_prior\n",
    "    return log_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "psd = from_string(inputs['psd'][0], n, delta_f, f_lower)\n",
    "psd = make_padded_frequency_series(psd, N, delta_f) # from global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "log_likelihood((0.06, 10),\n",
    "              20., 18., 15., 4096, psd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from pycbc.waveform import get_td_waveform\n",
    "h = get_td_waveform(approximant='ENIGMA', mass1 = 10, mass2 = 9, f_lower = 40,\n",
    "                   delta_t = 1./4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.environ['OMEGA_ATTACH'])\n",
    "print(os.environ['PN_ORDER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "* Main workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "num_steps = 5\n",
    "\n",
    "samplers = {}\n",
    "\n",
    "# Loop over all unique MCMC jobs\n",
    "for idx in range(len(inputs[inputs.keys()[0]])):\n",
    "    if True:\n",
    "        mass1 = inputs['mass1'][idx]\n",
    "        mass2 = inputs['mass2'][idx]\n",
    "        f_lower = inputs['f_lower'][idx]    \n",
    "        \n",
    "        psd = from_string(inputs['psd'][idx], n, delta_f, f_lower)\n",
    "        psd = make_padded_frequency_series(psd, N, delta_f) # from global settings\n",
    "        \n",
    "        # RUN THE SAMPLER\n",
    "        logging.warn(\"Initializing the MCMC sampler and burning-in\")\n",
    "        samplers[idx] = get_sampler([mass1, mass2, f_lower, sample_rate, psd])\n",
    "        \n",
    "        logging.warn(\"Running the MCMC sampler for {0} steps\".format(num_steps))\n",
    "        s, state = samplers[idx]\n",
    "        s.run_mcmc(state, num_steps)\n",
    "        \n",
    "        # WRite output from the sampler\n",
    "        write_output_from_sampler(\"OUT_FILE_NAME\", s, [mass1, mass2, f_lower, psd])\n",
    "        \n",
    "        # Early stop\n",
    "        if idx >= 0:\n",
    "            break\n",
    "    else:\n",
    "        logging.warn(\"Error in parameter set[{0}]: m1={1:.3f}, m2={2:.3f}, f_low={3:.0f}\".format(idx,\n",
    "                                                                                                mass1,\n",
    "                                                                                                mass2,\n",
    "                                                                                                f_lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import lalsimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "lalsimulation.SEOBNRv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "lalsimulation.ENIGMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "s, state = samplers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "state = s.run_mcmc(p0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "np.shape(state[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "state[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "s.run_mcmc(state[0], 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "s.run_mcmc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "log_prior_enigma([0.09, 12.51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "0 > -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### Visualize the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "\n",
    "samples = sampler.get_chain(flat=True)\n",
    "plt.axvline(0)\n",
    "plt.hist(samples[:, 0], 100, color=\"k\", histtype=\"step\")\n",
    "plt.xlabel(r\"$\\theta_1$\")\n",
    "plt.ylabel(r\"$p(\\theta_1)$\")\n",
    "plt.gca().set_yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### Check diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(\"Mean acceptance fraction: {0:.3f}\".format(np.mean(sampler.acceptance_fraction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Mean autocorrelation time: {0:.3f} steps\".format(\n",
    "        np.mean(sampler.get_autocorr_time())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycbc_enigma_retuning",
   "language": "python",
   "name": "pycbc_enigma_retuning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
