#!/usr/bin/env python
#
# Copyright (C) 2020 Prayush Kumar
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

"""Setup workflow to perform calibration of ENIGMA model using another BBH model """
import time
__itime__ = time.time()
import os
import sys
import itertools
import shutil
import argparse
import logging
import h5py
import numpy as np

from gwnrtools import __version__
from gwnrtools.stats.priors import default_bbh_params

############################################################
# command line usage
parser = argparse.ArgumentParser(usage=__file__ + " [--options]",
                                 description=__doc__)
parser.add_argument("--version", action="version", version=__version__,
                    help="Prints version information.")
parser.add_argument("--verbose", action="store_true", default=False,
                    help="Print logging messages.")
# Parameter ranges
parser.add_argument("--min-mass1", type=float, default=3.0,
                    help="Lower limit for mass of bigger BH.")
parser.add_argument("--max-mass1", type=float, default=100.0,
                    help="Upper limit for mass of bigger BH.")
parser.add_argument("--min-mass2", type=float, default=3.0,
                    help="Lower limit for mass of smaller BH.")
parser.add_argument("--max-mass2", type=float, default=100.0,
                    help="Upper limit for mass of smaller BH.")
parser.add_argument("--min-q", type=float, default=1.0,
                    help="Lower limit for mass of smaller BH.")
parser.add_argument("--max-q", type=float, default=10.0,
                    help="Upper limit for mass of smaller BH.")

parser.add_argument("--grid-spacing-mass1", type=float, default=1.0,
                    help="Step size for sampling mass of bigger BH.")
parser.add_argument("--grid-spacing-mass2", type=float, default=1.0,
                    help="Step size for sampling mass of smaller BH.")

parser.add_argument("--min-omega-attach", type=float, default=0.01,
                    help="Lower limit for dimless attachment freq.")
parser.add_argument("--max-omega-attach", type=float, default=0.1,
                    help="Upper limit for dimless attachment freq.")

# Discrete parameter choices
parser.add_argument("--params-to-mcmc-over", type=str, required=False,
                    default='a1,a2,a3,a4,b2,b3,b4',
                    help="Comma-separated list of parameters that we MCMC over")

parser.add_argument("--params-to-grid-over", type=str, required=False,
                    default='f_lower,psd',
                    help="Comma-separated list of parameters that are fixed during MCMC")

parser.add_argument("--choices-pn-order", type=str, required=False,
                    default='6,7,8,9,10,11,12',
                    help="Comma-separated list of PN orders to try")

parser.add_argument("--choices-f-lower", type=str, required=False,
                    default='15',
                    help="Comma-separated list of f_lowers to try")

parser.add_argument("--choices-psd", type=str, required=False,
                    default='aLIGOZeroDetHighPower',
                    help="Comma-separated list of PSDs to try")

parser.add_argument("--signal-approx", type=str, required=False,
                    default='SEOBNRv4_ROM',
                    help="Signal approximant to test against (FD)")

# MCMC and filtering options
parser.add_argument("--enigma-tag", type=str, required=True,
                    help="TAG that uniquely identifies the fit to be used.")
parser.add_argument("--num-samplers", type=int, default=32,
                    help="No of MCMC walkers")
parser.add_argument("--num-mcmc-steps", type=int, default=1000,
                    help="No of MCMC steps per walker")
parser.add_argument("--sample-rate", type=int, default=4096,
                    help="Sampling rate for wave gen and matches")
parser.add_argument("--time-length", type=int, default=32,
                    help="Expected max duration of waves")

# output options
parser.add_argument("--run-dir", type=str, required=False, default='.',
                    help="Run directory path.")
# output options
parser.add_argument("--output-prefix", type=str, required=False,
                    default='results/matches_vs_',
                    help="Input parameter file")


# parallelization options
parser.add_argument("--num-calcs-per-job", type=int, default=1,
                    help="Number of calculations per job ")


# parse command line
opts = parser.parse_args()

logging.getLogger().setLevel(logging.INFO)

############################################################
# inputs
range_of_mass1 = np.array([opts.min_mass1, opts.max_mass1])
range_of_mass2 = np.array([opts.min_mass2, opts.max_mass2])
range_of_q = np.array([opts.min_q, opts.max_q])
range_of_total_mass = np.array([opts.min_mass1 + opts.min_mass2,
                                opts.max_mass1 + opts.max_mass2])

# Dict of parameters that we allow gridding over
parameter_choices = {}
parameter_choices['mass1'] = np.arange(range_of_mass1[0],
                                       range_of_mass1[1],
                                       opts.grid_spacing_mass1)
parameter_choices['mass2'] = np.arange(range_of_mass2[0],
                                       range_of_mass2[1],
                                       opts.grid_spacing_mass2)
choices_f_ = []
for c in opts.choices_f_lower.split(","):
    try:
        choices_f_.append(float(c))
    except:
        pass
parameter_choices['f_lower'] = np.array(choices_f_)
parameter_choices['psd'] = opts.choices_psd.split(",")

# User input list of parameter names to grid over
parameters_to_grid_over = opts.params_to_grid_over.split(",")
assert np.all([p in parameter_choices for p in parameters_to_grid_over]),\
    "All parameters to grid over not recognized: {}".format(
        parameters_to_grid_over)

num_unique_mcmc_per_job = opts.num_calcs_per_job
run_directory = opts.run_dir

if opts.verbose:
    logging.info("Going to setup run with:")
    logging.info("Mass1 $\in$ [{0}, {1}]Msun".format(
        range_of_mass1[0], range_of_mass1[1]))
    logging.info("Mass2 $\in$ [{0}, {1}]Msun".format(
        range_of_mass2[0], range_of_mass2[1]))
    logging.info("Mass-ratio $\in$ [{0}, {1}]Msun".format(
        range_of_q[0], range_of_q[1]))
    logging.info("... with spacing: {0}, {1}".format(
        opts.grid_spacing_mass1, opts.grid_spacing_mass2))

    logging.info(
        "Will sample lower freq cutoff from: {}".format(opts.choices_f_lower))
    logging.info("Will sample PSD from: {}".format(opts.choices_psd))

    logging.info("Will setup {0} calculations per job".format(
        num_unique_mcmc_per_job))
    logging.info(
        " Setting up the workflow in {0} now ...\n".format(run_directory))
############################################################
# temporaries
__script_name__ = 'gwnrtools_enigma_sample_calib_parameters'
__submit_file_name__ = 'sampler.submit'

__submit_text__ = '''\
universe = vanilla
initialdir = {11}
executable = scripts/{10}
arguments = " --job-id $(macrojobid) --param-file $(macroparamfile) --min-omega-attach {0} --max-omega-attach {1} --choices-pn-order {2} --signal-approx {3} --num-samplers {4} --num-mcmc-steps {5} --sample-rate {6} --time-length {7} --output-prefix {8} --enigma-tag {9}"
accounting_group = ligo.dev.o3.cbc.explore.test
getenv = True
log = /usr1/prayush.kumar/tmpc8uHuQ
error = log/gwnrtools_enigma_sample_parameters-$(cluster)-$(process).err
output = log/gwnrtools_enigma_sample_parameters-$(cluster)-$(process).out
notification = never
queue 1
'''.format(
    opts.min_omega_attach,
    opts.max_omega_attach,
    opts.choices_pn_order,
    opts.signal_approx,
    opts.num_samplers,
    opts.num_mcmc_steps,
    opts.sample_rate,
    opts.time_length,
    opts.output_prefix,
    opts.enigma_tag,
    __script_name__,
    os.path.abspath(run_directory)
)


def job_id(job_num):
    return '{:06d}'.format(job_num)


def dag_file():
    return 'retune_enigma.dag'


def parameter_file(job_id):
    return os.path.join('input/parameters_{0}.hdf'.format(job_id))


def group_name(i):
    return '{0:06d}'.format(i)


def write_parameter_file(job_id, params):
    '''Outdated'''
    file_name = os.path.join('input/parameters_{0}.hdf'.format(job_id))
    if os.path.exists(file_name):
        return file_name
    with h5py.File(file_name, 'a') as fout:
        for param_name in params:
            fout.create_dataset(param_name, data=list(
                np.array(params[param_name])))
    return file_name


def write_parameters_to_group(fout, group_name, params):
    gout = fout.create_group(group_name)
    for param_name in params:
        gout.create_dataset(param_name, data=list(params[param_name]))


def write_job_to_dag(job_id, param_file):
    with open(dag_file(), 'a+') as fout:
        fout.write('''\
JOB TUNE{0} {2}
VARS TUNE{0} macrojobid="{0}"
VARS TUNE{0} macroparamfile="{1}"

'''.format(job_id, param_file, __submit_file_name__))


############################################################
# Setup

# Move to run directory
if not os.path.exists(run_directory):
    os.makedirs(run_directory)
os.chdir(run_directory)

# Make directories
dirs_to_make = ['scripts', 'input', 'results', 'log']
for d in dirs_to_make:
    if not os.path.exists(d):
        os.makedirs(d)

sampling_prog = os.popen('which {0}'.format(__script_name__)).read().strip()
shutil.copy(sampling_prog, 'scripts/{0}'.format(__script_name__))
os.chmod('scripts/{0}'.format(__script_name__), 0o0777)

logging.info(".. run directories setup.")

############################################################
# Make the grid
grid_choices = list(itertools.product(
    *[parameter_choices[p] for p in parameters_to_grid_over]))

jobs = {}

num_mcmc_in_job = 1e9
job_num = 0
job_params = None

for p_vector in grid_choices:
    # Choose parameters for this MCMC exploration
    # 1. Use parameters from the current grid choice
    curr_p = {p: [p_vector[i]] for i, p in enumerate(parameters_to_grid_over)}
    if 'mass1' in curr_p and 'mass2' in curr_p:
        a, b = curr_p['mass1'][0], curr_p['mass2'][0]
        curr_p['mass1'] = [max(a, b)]
        curr_p['mass2'] = [min(a, b)]
    # 2. Use parameters that are user input here
    # If any of the parameters below are to be gridded over
    # they should not be populated below
    if 'mass1' not in curr_p:
        curr_p['mass1'] = list(range_of_mass1)
    if 'mass2' not in curr_p:
        curr_p['mass2'] = list(range_of_mass2)
    if 'q' not in curr_p:
        if 'mass1' in parameters_to_grid_over and 'mass2' in parameters_to_grid_over:
            print("CHOOSING q 1: {}, {}, {}".format(
                curr_p['mass1'][0], curr_p['mass2'][0], curr_p['mass1'][0] / curr_p['mass2'][0]))
            curr_p['q'] = [curr_p['mass1'][0] / curr_p['mass2'][0]]
        elif 'mass1' in curr_p and 'mass2' in curr_p:
            print("CHOOSING q 2")
            curr_p['q'] = list([np.minimum(curr_p['mass1'][0])/np.maximum(curr_p['mass2'][0]),
                                np.maximum(curr_p['mass1'][0])/np.minimum(curr_p['mass2'][0])])
        else:
            print("CHOOSING q 3")
            curr_p['q'] = list(range_of_q)
    if 'total_mass' not in curr_p:
        if 'mass1' in parameters_to_grid_over and 'mass2' in parameters_to_grid_over:
            print("CHOOSING M 1: {}, {}, {}".format(
                curr_p['mass1'][0], curr_p['mass2'][0], curr_p['mass1'][0] + curr_p['mass2'][0]))
            curr_p['total_mass'] = [curr_p['mass1'][0] + curr_p['mass2'][0]]
        elif 'mass1' in curr_p and 'mass2' in curr_p:
            print("CHOOSING M 2")
            curr_p['total_mass'] = list([np.minimum(curr_p['mass1'])+np.minimum(curr_p['mass2']),
                                         np.maximum(curr_p['mass1'])+np.maximum(curr_p['mass2'])])
        else:
            print("CHOOSING M 3")
            curr_p['total_mass'] = list(range_of_total_mass)
    # 3. Set remaining parameters to their default BBH values
    for p in default_bbh_params.columns:
        if str(p) not in curr_p:
            curr_p[p] = default_bbh_params[p]['range']

    logging.info("Using parameters: {}".format(curr_p))

    # Set job info for DAG formation
    if num_mcmc_in_job < num_unique_mcmc_per_job:
        # add to current job
        job_params.append(curr_p)

        num_mcmc_in_job += 1
        job_num += 1
    else:
        # close current job
        if job_params:
            jobs[curr_job_id] = job_params

        # start new job
        curr_job_id = job_id(job_num)
        job_params = [curr_p]

        num_mcmc_in_job = 1
        job_num += 1

# Leftover jobs
if job_params:
    jobs[curr_job_id] = job_params
    job_params = None

for k in jobs:
    for curr_k in jobs[k]:
        print("\n JOB {}: {}\n".format(k, curr_k))

logging.info(" .. parameter grid constructed.")
############################################################
# Write submit file
with open(__submit_file_name__, "w") as fout:
    fout.write(__submit_text__)

logging.info(" .. condor submission file written.")
############################################################


# Design DAG
# Iterate over the grid, and add a job for each!
for _job_id in jobs:
    job_params = jobs[_job_id]

    parameter_file_name = parameter_file(_job_id)
    with h5py.File(parameter_file_name, 'a') as fout:
        # Iterate over unique MCMC jobs
        for i, jp in enumerate(job_params):
            job_params_dict = {}
            for p in set(parameters_to_grid_over).union(set(default_bbh_params.columns)):
                job_params_dict[p] = jp[p]
            write_parameters_to_group(fout, group_name(i), job_params_dict)

    write_job_to_dag(_job_id, parameter_file_name)

logging.info(" .. DAG written.")
logging.info("All Done in {0} seconds".format(time.time() - __itime__))
