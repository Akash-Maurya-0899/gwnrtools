#!/usr/bin/env python
#
# Copyright (C) 2020 Prayush Kumar
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

"""Perform calibration runs for ENIGMA model using another BBH model """

import time
__itime__ = time.time()

import os
import sys
import h5py
import numpy as np
import argparse
import logging
from multiprocessing import Pool
import pandas as pd

from gwnrtools import __version__
from gwnrtools.utils import make_padded_frequency_series
from gwnrtools.stats.samplers import (
    get_emcee_ensemble_sampler, write_output_from_emcee_sampler)
from gwnrtools.stats.enigma_utils import (
    log_prior_enigma, log_likelihood_enigma, log_prob_enigma,
    __order_of_sampled_params__)

from pycbc.psd import from_string

############################################################
# command line usage
parser = argparse.ArgumentParser(usage=__file__ + " [--options]",
                                 description=__doc__)
parser.add_argument("--version", action="version", version=__version__,
                    help="Prints version information.")
parser.add_argument("--verbose", action="store_true", default=False,
                    help="Print logging messages.")

# workflow options
parser.add_argument("--job-id", type=str, required=True)
parser.add_argument("--param-file", type=str, required=True,
                    help="Input parameter file")
parser.add_argument("--min-omega-attach", type=float, default=0.01,
                    help="Lower limit for dimless attachment freq.")
parser.add_argument("--max-omega-attach", type=float, default=0.1,
                    help="Upper limit for dimless attachment freq.")

parser.add_argument("--choices-pn-order", type=str, required=False,
                    default='6,7,8,9,10,11,12',
                    help="Comma-separated list of PN orders to try")

parser.add_argument("--signal-approx", type=str, required=False,
                    default='SEOBNRv4_ROM',
                    help="Signal approximant to test against (FD)")

parser.add_argument("--num-samplers", type=int, default=32,
                    help="No of MCMC walkers")
parser.add_argument("--num-mcmc-steps", type=int, default=100,
                    help="No of MCMC steps per walker")
parser.add_argument("--sample-rate", type=int, default=4096,
                    help="Sampling rate for wave gen and matches")
parser.add_argument("--time-length", type=int, default=32,
                    help="Expected max duration of waves")

parser.add_argument("--use-dilation-map-match",
                    action="store_true", default=False,
                    help="use a nonlinear dilating map for match")
# parallelization options
parser.add_argument("--num-processes", type=int, default=2,
                    help="No of Multiprocessing processes")

# output options
parser.add_argument("--output-prefix", type=str, required=False,
                    default='results/matches_vs_',
                    help="Input parameter file")

# parse command line
opts = parser.parse_args()

logging.getLogger().setLevel(logging.INFO)

############################################################
# inputs
inputs = {}

inputs['job_id'] = opts.job_id
inputs['param_file'] = opts.param_file
inputs['signal_approx'] = opts.signal_approx
inputs['output_prefix'] = opts.output_prefix + '{0}'.format(opts.signal_approx)
inputs['use_dilation_map_match'] = opts.use_dilation_map_match

# MCMC params
inputs['num_samplers'] = opts.num_samplers
inputs['num_steps'] = opts.num_mcmc_steps

# Filtering params
inputs['sample_rate'] = opts.sample_rate
inputs['time_length'] = opts.time_length

inputs['delta_t'] = 1. / inputs['sample_rate']
inputs['delta_f'] = 1. / inputs['time_length']
N = inputs['sample_rate'] * inputs['time_length']
n = N / 2 + 1

############################################################
# Setup
with h5py.File(inputs['param_file'], 'r') as fin:
    inputs['fixed_params'] = (list(fin.keys()),)
    for k in fin:
        inputs[k] = fin[k][()]
        if type(inputs[k][0]) is not list:
            inputs[k] = [[inputs[k][0]], ]

inputs = pd.DataFrame.from_dict(inputs)
logging.info(".. input parameters read.")

# Parameters to sample in (and dependent ones to specify priors on)
sampling_params = {}

sampling_params['q'] = ('continuous', [1., 4.])
sampling_params['total_mass'] = ('continuous', [10., 100.])
# calibration params
sampling_params['omega_attach'] = (
    'continuous', [opts.min_omega_attach, opts.max_omega_attach])
sampling_params['PNO'] = ('discrete', [int(pno_)
                                       for pno_ in opts.choices_pn_order.split(",")])
sampling_params['a1'] = ('continuous', [-1., 1.])
sampling_params['a2'] = ('continuous', [-1., 1.])
sampling_params['a3'] = ('continuous', [-1., 1.])
sampling_params['a4'] = ('continuous', [-1., 1.])

sampling_params['b2'] = ('continuous', [-1., 1.])
sampling_params['b3'] = ('continuous', [-1., 1.])
sampling_params['b4'] = ('continuous', [-1., 1.])

sampling_params = pd.DataFrame.from_dict(sampling_params)
sampling_params = sampling_params.set_index(pd.Index(['vartype', 'range']))


if opts.verbose:
    logging.info("Starting job: {}".format(inputs.job_id[0]))
    logging.info("Will read from: {}".format(inputs.param_file[0]))
    logging.info("Will compute matches against {}".format(
        inputs.signal_approx[0]))
    logging.info("Will sample omega_att: [{0}, {1}]".format(
        *sampling_params.omega_attach.range))
    logging.info("Will sample PN order from: {}".format(
        sampling_params.PNO.range))
    logging.info("Will take {} MCMC steps per sampler".format(
        inputs.num_steps[0]))
    logging.info("Will use {} samplers".format(inputs.num_samplers[0]))
    logging.info("Will write output with prefix: {}".format(
        inputs.output_prefix[0]))
    logging.info("Will filter at {0}Hz with maxT = {1}secs".format(
        inputs.sample_rate[0], inputs.time_length[0]))


############################################################
# Functions and classes
def output_file(prefix, job_id, idx):
    return prefix + '{0}_{1:06d}.dat'.format(job_id, idx)


############################################################
sampling_params['sampler_params'] = ('discrete', __order_of_sampled_params__)
inputs['sampler_params'] = (__order_of_sampled_params__,)

############################################################
# Create and run samplers, store output
try:
    __my_pool__ = Pool(processes=opts.num_processes)
except:
    __my_pool__ = None

samplers = {}
old_f_lower = -1

# Loop over all unique MCMC jobs
try:
    num_mcmc = len(inputs[inputs.fixed_params[0][0]][0])
except:
    num_mcmc = 1
for idx in range(num_mcmc):
    try:
        f_lower = inputs['f_lower'][0][idx]
        df = inputs['delta_f'][0]
        dt = inputs['delta_t'][0]
        sample_rate = 1. / dt
        N = int(1. / dt / df)
        n = N / 2 + 1

        if opts.verbose:
            logging.info(
                "\n\n ... starting MCMC for setting {0}/{1}: f_low={2:.0f}".format(idx,
                                                                                   len(inputs[inputs.keys()[
                                                                                       0]]),
                                                                                   f_lower))

        if f_lower != old_f_lower:
            # from global settings
            psd = from_string(inputs['psd'][0][idx], n, df, f_lower)
            psd = make_padded_frequency_series(psd, N, df)
            old_f_lower = f_lower

        # RUN THE SAMPLER
        logging.info("... Initializing the MCMC sampler and burning-in")
        hdf_backend = output_file(inputs['output_prefix'][0],
                                  inputs['job_id'][0],
                                  idx).replace('.dat', '.h5')
        samplers[idx] = \
            get_emcee_ensemble_sampler(log_prob,
                                       sampling_params[sampling_params['sampler_params'].range],
                                       [inputs.iloc[0],
                                        f_lower, sampling_params, psd],
                                       kwargs={
                                           'dilation_map_match': inputs['use_dilation_map_match'][0]},
                                       backend_hdf=hdf_backend,
                                       nwalkers=inputs.num_samplers[0],
                                       pool=__my_pool__)

        logging.info(
            "... Running the MCMC sampler for {0} steps".format(inputs.num_steps[0]))
        s, state, p0 = samplers[idx]
        try:
            s.run_mcmc(None, inputs.num_steps[0])
        except ValueError:
            s.run_mcmc(p0, inputs.num_steps[0])

        # WRite output from the sampler
        logging.info("... Writing output now..")
        write_output_from_emcee_sampler(output_file(inputs['output_prefix'][0],
                                                    inputs['job_id'][0],
                                                    idx),
                                        s,
                                        sampling_params[sampling_params['sampler_params'].range])

        logging.info("... Written output!")
        # Early stop
        if idx >= 1e9:
            break
    except:
        logging.error("Error in parameter set[{0}]: f_low={1:.0f}".format(idx,
                                                                          f_lower))
        raise
__my_pool__.close()
__my_pool__.terminate()
logging.info(" .. MCMC samples written.")
logging.info("All Done in {0} seconds".format(time.time() - __itime__))
